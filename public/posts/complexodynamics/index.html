<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Complextropy and Complexodynamics - Sutskever Reading List Series (1 of 30) | Perspective Tensor</title>
<meta name="keywords" content="">
<meta name="description" content="

What exactly is complexity? What is there to model? I&rsquo;ve been preoccupied with these ideas recently, especially after exploring Ilya Sutskever&rsquo;s highly recommended top 30 machine learning reading list. This aligns closely with my writing about compression. It&rsquo;s just another way of looking at how to model complex yet intelligent systems — a.k.a. creating ML models or &ldquo;AI,&rdquo; a term that&rsquo;s overused these days.
Anyway, let&rsquo;s start with a very &ldquo;simple&rdquo; concept — entropy. You might have noticed it in my handle, &ldquo;entropy warrior.&rdquo; What exactly does entropy mean? You can easily find a definition with a quick Google search. Here&rsquo;s what the latest Google AI search function tells us:">
<meta name="author" content="Lin Wang">
<link rel="canonical" href="https://entropy-warrior.github.io/posts/complexodynamics/">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
<link crossorigin="anonymous" href="/assets/css/stylesheet.c5de734fbd88c3d21543485ffbcb1ccdda89a86a780cf987fa00199c41dbc947.css" integrity="sha256-xd5zT72Iw9IVQ0hf&#43;8sczdqJqGp4DPmH&#43;gAZnEHbyUc=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://entropy-warrior.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://entropy-warrior.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://entropy-warrior.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://entropy-warrior.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://entropy-warrior.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://entropy-warrior.github.io/posts/complexodynamics/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Complextropy and Complexodynamics - Sutskever Reading List Series (1 of 30)" />
<meta property="og:description" content="

What exactly is complexity? What is there to model? I&rsquo;ve been preoccupied with these ideas recently, especially after exploring Ilya Sutskever&rsquo;s highly recommended top 30 machine learning reading list. This aligns closely with my writing about compression. It&rsquo;s just another way of looking at how to model complex yet intelligent systems — a.k.a. creating ML models or &ldquo;AI,&rdquo; a term that&rsquo;s overused these days.
Anyway, let&rsquo;s start with a very &ldquo;simple&rdquo; concept — entropy. You might have noticed it in my handle, &ldquo;entropy warrior.&rdquo; What exactly does entropy mean? You can easily find a definition with a quick Google search. Here&rsquo;s what the latest Google AI search function tells us:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://entropy-warrior.github.io/posts/complexodynamics/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-06-29T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-06-29T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Complextropy and Complexodynamics - Sutskever Reading List Series (1 of 30)"/>
<meta name="twitter:description" content="

What exactly is complexity? What is there to model? I&rsquo;ve been preoccupied with these ideas recently, especially after exploring Ilya Sutskever&rsquo;s highly recommended top 30 machine learning reading list. This aligns closely with my writing about compression. It&rsquo;s just another way of looking at how to model complex yet intelligent systems — a.k.a. creating ML models or &ldquo;AI,&rdquo; a term that&rsquo;s overused these days.
Anyway, let&rsquo;s start with a very &ldquo;simple&rdquo; concept — entropy. You might have noticed it in my handle, &ldquo;entropy warrior.&rdquo; What exactly does entropy mean? You can easily find a definition with a quick Google search. Here&rsquo;s what the latest Google AI search function tells us:"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://entropy-warrior.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Complextropy and Complexodynamics - Sutskever Reading List Series (1 of 30)",
      "item": "https://entropy-warrior.github.io/posts/complexodynamics/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Complextropy and Complexodynamics - Sutskever Reading List Series (1 of 30)",
  "name": "Complextropy and Complexodynamics - Sutskever Reading List Series (1 of 30)",
  "description": " What exactly is complexity? What is there to model? I\u0026rsquo;ve been preoccupied with these ideas recently, especially after exploring Ilya Sutskever\u0026rsquo;s highly recommended top 30 machine learning reading list. This aligns closely with my writing about compression. It\u0026rsquo;s just another way of looking at how to model complex yet intelligent systems — a.k.a. creating ML models or \u0026ldquo;AI,\u0026rdquo; a term that\u0026rsquo;s overused these days.\nAnyway, let\u0026rsquo;s start with a very \u0026ldquo;simple\u0026rdquo; concept — entropy. You might have noticed it in my handle, \u0026ldquo;entropy warrior.\u0026rdquo; What exactly does entropy mean? You can easily find a definition with a quick Google search. Here\u0026rsquo;s what the latest Google AI search function tells us:\n",
  "keywords": [
    
  ],
  "articleBody": " What exactly is complexity? What is there to model? I’ve been preoccupied with these ideas recently, especially after exploring Ilya Sutskever’s highly recommended top 30 machine learning reading list. This aligns closely with my writing about compression. It’s just another way of looking at how to model complex yet intelligent systems — a.k.a. creating ML models or “AI,” a term that’s overused these days.\nAnyway, let’s start with a very “simple” concept — entropy. You might have noticed it in my handle, “entropy warrior.” What exactly does entropy mean? You can easily find a definition with a quick Google search. Here’s what the latest Google AI search function tells us:\n“Entropy is a fundamental concept in physics, particularly in thermodynamics and information theory, that essentially measures the degree of randomness, disorder, or uncertainty within a system. It describes the unavailability of a system’s energy to do practical work and the tendency of systems to move towards a state of greater disorder or equilibrium.”\nI have to say, it’s quite a good definition — albeit a bit too wordy for my taste. For me, in the simplest terms, entropy is “randomness.” Anti-entropy is “order.” A slight digression here: my handle’s meaning should be obvious — I want to seek order and meaning from the randomness that we are all inevitably marching towards.\nWith that out of the way, let’s get back to what I want to discuss today — Complexodynamics. What is it exactly? After reading Scott Aaronson’s blog post, which I highly recommend, it describes an intuitive but hard-to-define term: “sophistication,” “interestingness,” or in this tongue-in-cheek blog, “complexodynamics.” A picture is worth a thousand words — let’s take a look at the banner image above.\nFrom left to right, entropy increases constantly: first, milk and coffee are orderly separated, then they start mixing, creating beautiful and interesting patterns, and finally, they are thoroughly mixed.\nBut if you take another look at them and try answering this question: “How do you succinctly describe the exact state of the liquid inside the three glasses?” You’ll find that the two glasses on the sides are easy, yet the middle one is rather difficult. After all, how can you precisely define that swirly pattern?\nThis effort required to describe these states is “complextropy.” I like the other definition the blogger used: “sophistication.” If you think about how complextropy evolves through a time series of coffee and milk mixing, you’ll observe the following pattern:\nEntropy always increases, but meaningfulness — a.k.a. sophistication, a.k.a. complexity — peaks somewhere along the way.\nSo what does all this matter? Why should we care? It may not be obvious at first, but I think it’s quite deep and brings a new perspective to how we think about building AI/ML systems. Without going too deep into the formalism of defining complextropy rigorously — I highly recommend reading it, especially the part about limiting the definition with tangible compute available — here are my takeaways:\nThe Extremes Tell Us Little\nBoth extremely random and extremely simple systems, when considered in isolation, have the least amount of useful information. They can be described and modeled easily, yet the models themselves don’t provide much utility. To describe how a system evolves, you’ll have to observe the dynamics over time — how they change. The most interesting part usually happens somewhere in the middle — the part that gives you insight into the mechanisms behind the complex behavior.\nFrom States to Mechanisms\nEntropy defines a state, while sophistication defines how much information can be used to deduce the underlying mechanisms — which is arguably the most important part when it comes to machine learning. It’s not just about capturing the current configuration; it’s about understanding the processes that create and transform these configurations.\nImplications for AI/ML\nThis perspective suggests that the most valuable models aren’t necessarily those that perfectly capture every detail (maximum entropy) or those that oversimplify (minimum entropy), but those that find the sweet spot where complexity reveals structure. This is where patterns emerge, where we can extract meaningful insights, and where our models become truly intelligent rather than merely descriptive.\nAs we continue to build more sophisticated AI systems, remembering this principle of complexodynamics might help us focus not just on accuracy or efficiency, but on capturing the meaningful complexity that lies at the heart of intelligent behavior.\nReference:\nAaronson, S. (2011). Why Philosophers Should Care About Computational Complexity. Shtetl-Optimized Blog. ",
  "wordCount" : "740",
  "inLanguage": "en",
  "datePublished": "2025-06-29T00:00:00Z",
  "dateModified": "2025-06-29T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Lin Wang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://entropy-warrior.github.io/posts/complexodynamics/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Perspective Tensor",
    "logo": {
      "@type": "ImageObject",
      "url": "https://entropy-warrior.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://entropy-warrior.github.io/" accesskey="h" title="Perspective Tensor (Alt + H)">Perspective Tensor</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://entropy-warrior.github.io/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://entropy-warrior.github.io/codes/" title="Codes">
                    <span>Codes</span>
                </a>
            </li>
            <li>
                <a href="https://entropy-warrior.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://www.linkedin.com/in/linwang4ds/" title="">
                    <span><i class="fab fa-linkedin"></i></span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://entropy-warrior.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://entropy-warrior.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Complextropy and Complexodynamics - Sutskever Reading List Series (1 of 30)
    </h1>
    <div class="post-meta"><span title='2025-06-29 00:00:00 +0000 UTC'>June 29, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Lin Wang

</div>
  </header> 

  <div class="post-content"><p><img loading="lazy" src="/images/coffee-mixing-stages.png" alt="banner"  />
</p>
<p>What exactly is complexity? What is there to model? I&rsquo;ve been preoccupied with these ideas recently, especially after exploring Ilya Sutskever&rsquo;s highly recommended top 30 machine learning reading list. This aligns closely with my writing about compression. It&rsquo;s just another way of looking at how to model complex yet intelligent systems — a.k.a. creating ML models or &ldquo;AI,&rdquo; a term that&rsquo;s overused these days.</p>
<p>Anyway, let&rsquo;s start with a very &ldquo;simple&rdquo; concept — entropy. You might have noticed it in my handle, &ldquo;entropy warrior.&rdquo; What exactly does entropy mean? You can easily find a definition with a quick Google search. Here&rsquo;s what the latest Google AI search function tells us:</p>
<blockquote>
<p>&ldquo;Entropy is a fundamental concept in physics, particularly in thermodynamics and information theory, that essentially measures the degree of randomness, disorder, or uncertainty within a system. It describes the unavailability of a system&rsquo;s energy to do practical work and the tendency of systems to move towards a state of greater disorder or equilibrium.&rdquo;</p></blockquote>
<p>I have to say, it&rsquo;s quite a good definition — albeit a bit too wordy for my taste. For me, in the simplest terms, entropy is &ldquo;randomness.&rdquo; Anti-entropy is &ldquo;order.&rdquo; A slight digression here: my handle&rsquo;s meaning should be obvious — I want to seek order and meaning from the randomness that we are all inevitably marching towards.</p>
<p>With that out of the way, let&rsquo;s get back to what I want to discuss today — Complexodynamics. What is it exactly? After reading <a href="https://scottaaronson.blog/?p=762">Scott Aaronson&rsquo;s blog post</a>, which I highly recommend, it describes an intuitive but hard-to-define term: &ldquo;sophistication,&rdquo; &ldquo;interestingness,&rdquo; or in this tongue-in-cheek blog, &ldquo;complexodynamics.&rdquo; A picture is worth a thousand words — let&rsquo;s take a look at the banner image above.</p>
<p>From left to right, entropy increases constantly: first, milk and coffee are orderly separated, then they start mixing, creating beautiful and interesting patterns, and finally, they are thoroughly mixed.</p>
<p>But if you take another look at them and try answering this question: &ldquo;How do you succinctly describe the exact state of the liquid inside the three glasses?&rdquo; You&rsquo;ll find that the two glasses on the sides are easy, yet the middle one is rather difficult. After all, how can you precisely define that swirly pattern?</p>
<p>This effort required to describe these states is &ldquo;complextropy.&rdquo; I like the other definition the blogger used: &ldquo;sophistication.&rdquo; If you think about how complextropy evolves through a time series of coffee and milk mixing, you&rsquo;ll observe the following pattern:</p>
<p><img loading="lazy" src="/images/complextropy-evolution.png" alt="Complextropy evolution graph"  />
</p>
<p>Entropy always increases, but meaningfulness — a.k.a. sophistication, a.k.a. complexity — peaks somewhere along the way.</p>
<p>So what does all this matter? Why should we care? It may not be obvious at first, but I think it&rsquo;s quite deep and brings a new perspective to how we think about building AI/ML systems. Without going too deep into the formalism of defining complextropy rigorously — I highly recommend reading it, especially the part about limiting the definition with tangible compute available — here are my takeaways:</p>
<p><strong>The Extremes Tell Us Little</strong></p>
<p>Both extremely random and extremely simple systems, when considered in isolation, have the least amount of useful information. They can be described and modeled easily, yet the models themselves don&rsquo;t provide much utility. To describe how a system evolves, you&rsquo;ll have to observe the dynamics over time — how they change. The most interesting part usually happens somewhere in the middle — the part that gives you insight into the mechanisms behind the complex behavior.</p>
<p><strong>From States to Mechanisms</strong></p>
<p>Entropy defines a state, while sophistication defines how much information can be used to deduce the underlying mechanisms — which is arguably the most important part when it comes to machine learning. It&rsquo;s not just about capturing the current configuration; it&rsquo;s about understanding the processes that create and transform these configurations.</p>
<p><strong>Implications for AI/ML</strong></p>
<p>This perspective suggests that the most valuable models aren&rsquo;t necessarily those that perfectly capture every detail (maximum entropy) or those that oversimplify (minimum entropy), but those that find the sweet spot where complexity reveals structure. This is where patterns emerge, where we can extract meaningful insights, and where our models become truly intelligent rather than merely descriptive.</p>
<p>As we continue to build more sophisticated AI systems, remembering this principle of complexodynamics might help us focus not just on accuracy or efficiency, but on capturing the meaningful complexity that lies at the heart of intelligent behavior.</p>
<hr>
<p><strong>Reference:</strong></p>
<ol>
<li><a href="https://scottaaronson.blog/?p=762">Aaronson, S. (2011). Why Philosophers Should Care About Computational Complexity. Shtetl-Optimized Blog.</a></li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="https://entropy-warrior.github.io/posts/landing/">
    <span class="title">Next »</span>
    <br>
    <span>👋 Welcome to Lin&#39;s blog!</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://entropy-warrior.github.io/">Perspective Tensor</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
